# ‚öõÔ∏è CodeSearch AI

> Semantic search engine for React documentation powered by RAG (Retrieval-Augmented Generation)

[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-latest-green)](https://langchain.com/)
[![Redis](https://img.shields.io/badge/Redis-7-red)](https://redis.io/)
[![Groq](https://img.shields.io/badge/Groq-Llama_3.1-orange)](https://groq.com/)

[üöÄ Live Demo](#) | [üìπ Video Demo](#) | [üìù Blog Post](#)

---

## üéØ The Problem

React documentation contains **500+ pages** of content. Traditional keyword search fails for semantic queries like:
- *"How do I optimize performance?"*
- *"What's the best way to handle forms?"*
- *"Show me patterns for data fetching"*

Developers waste time searching through docs manually or settling for Stack Overflow answers that might be outdated.

---

## ‚ú® The Solution

CodeSearch AI uses **Retrieval-Augmented Generation (RAG)** to:
1. Understand questions in natural language
2. Retrieve relevant sections from official React docs
3. Generate accurate answers with working code examples
4. Cite sources so you can dive deeper

**Plus**: Redis caching provides **sub-3ms responses** for repeated queries.

---

## üöÄ Key Features

- üí¨ **Natural Language Queries** - Ask questions like you would a colleague
- üíª **100% Code Coverage** - Every answer includes working code examples
- üìö **Source Citations** - Direct links to official React documentation
- ‚ö° **Lightning Fast Caching** - 1049x speedup with Redis (2.94s ‚Üí 0.003s)
- üìä **Real-Time Metrics** - Track performance and cache efficiency
- üéØ **High Accuracy** - 100% success rate on diverse test queries

---

## üìä Performance Metrics

Tested with **25 diverse React queries** covering beginner to advanced topics:

### Response Times
- **Average (All Queries)**: 2.35s
- **Average (Cached)**: 0.003s ‚ö°
- **Average (Uncached)**: 2.94s
- **Cache Speedup**: **1049x faster**

### Accuracy & Quality
- **Success Rate**: 100% (25/25 queries)
- **Code Examples**: 100% (25/25 responses)
- **Average Sources per Query**: 2.8 relevant docs
- **Cache Hit Rate**: 42.86% (exceeds 40% target)

### Resource Efficiency
- **Memory Usage**: 1.17 MB for 20 cached queries
- **Latency**: Sub-3ms for cached responses
- **Scalability**: Redis-ready for horizontal scaling

---

## üèóÔ∏è Architecture

[![](https://mermaid.ink/img/pako:eNqVVe1uo0YUfZURq2i3Wkz5MMZG1VYJuHGksIrBtlbF-2M8XGwUYLwzsImbjdTn6L_20fZJOjCOjZM2VZGQ59y598z9OIMfFEITUFxlzfB2g2YXyxKJh9craZhzYOiqrIClmIDcbJ553O5Ma2A796cV-_HD2wm9QwlFV6jm0LxRhSv4-e1nGQRlsiyfkXuYbABd4x2wI3PoPYSQZFzuttR9UxsOztAkq1AoOB-Pzt4kliRir3XVNV23OPr-x5-fO17B3ivIOG_dPFpWWVkDqigKzy9fyVHsoptsC3lWdsqfjuO2dDQuVpAkWbluaT_SIiM9aGy9Cu6rTg6LKF4AqShDEWBGNjKNDaMF9i9aMKNbZCGfEt5NffYpbpIVZOicc0Gd71rvECqWwVdIkLepy9tuzPV1EIsXXUIJDFcZLduI6xwXGFmagRxdnnjJ6Bd0fnPViQ3HURwC39KSg5zrecnvxKTfI08IRfxEtGYE-Cst83GFUSRK7TRs4V_E7_YNaPZXmMPLFti6_l5oiPAfuin58bvnijA0w0GBDDJ19EXMIoND1D8lFTT9IvxIG8Q3QtSUFbgkgGYMk1sxRlnz99__Qk9dQLOsgINV6qiRNj_YopqIhvBWmy8zODtDv-T0ToI56vU-CIlLFHoN_Ca0-00o-cTWKFUYA2n0Jm3cfI-CFk3HEk7HLVxEEi4iCf39VRYL1NNCyOErLqtWX9pLd6GzPfnsU2sQApKGRklt0uN9hFi8qEJrx93whv6p1_wUBp22RNVO3Kq1xCTHnPuQItJ0-GOjtTTLc_dNmg5Wg5XKK0ZvwX1DRiY28R727rKk2rjW9l4lNKes8U6f8TG87rD1E7xKnQObMXIMYp6yma-xJUK7HTrbIOlgcKAz0xH0-_-DTnwm2UmtSd861prao1TX_7VWXdef0RVS5B3GkePYKT4w2qmVkP9IsMMp9PqUYdcaeqo3Ub1ADf3juLoO07G6iFQhJVWoR21mv59C16kR5lM7u_agW4aiin-mLFHcitWgKgWI-9pA5aEJWSrVBgpYKq5YJpjdLpVl-Shitrj8ldLiKYzRer1R3BTnXKB6K44FP8Piy1AcrEzcWWAerctKcUctheI-KPeKO9C1od3vm4bl6EbfMBxV2Snu0NJGAjpDwzHt4dAaPKrKb-2ZumZb-sAZWpYxtI2RPTIf_wYi30ch?type=png)](https://mermaid.live/edit#pako:eNqVVe1uo0YUfZURq2i3Wkz5MMZG1VYJuHGksIrBtlbF-2M8XGwUYLwzsImbjdTn6L_20fZJOjCOjZM2VZGQ59y598z9OIMfFEITUFxlzfB2g2YXyxKJh9craZhzYOiqrIClmIDcbJ553O5Ma2A796cV-_HD2wm9QwlFV6jm0LxRhSv4-e1nGQRlsiyfkXuYbABd4x2wI3PoPYSQZFzuttR9UxsOztAkq1AoOB-Pzt4kliRir3XVNV23OPr-x5-fO17B3ivIOG_dPFpWWVkDqigKzy9fyVHsoptsC3lWdsqfjuO2dDQuVpAkWbluaT_SIiM9aGy9Cu6rTg6LKF4AqShDEWBGNjKNDaMF9i9aMKNbZCGfEt5NffYpbpIVZOicc0Gd71rvECqWwVdIkLepy9tuzPV1EIsXXUIJDFcZLduI6xwXGFmagRxdnnjJ6Bd0fnPViQ3HURwC39KSg5zrecnvxKTfI08IRfxEtGYE-Cst83GFUSRK7TRs4V_E7_YNaPZXmMPLFti6_l5oiPAfuin58bvnijA0w0GBDDJ19EXMIoND1D8lFTT9IvxIG8Q3QtSUFbgkgGYMk1sxRlnz99__Qk9dQLOsgINV6qiRNj_YopqIhvBWmy8zODtDv-T0ToI56vU-CIlLFHoN_Ca0-00o-cTWKFUYA2n0Jm3cfI-CFk3HEk7HLVxEEi4iCf39VRYL1NNCyOErLqtWX9pLd6GzPfnsU2sQApKGRklt0uN9hFi8qEJrx93whv6p1_wUBp22RNVO3Kq1xCTHnPuQItJ0-GOjtTTLc_dNmg5Wg5XKK0ZvwX1DRiY28R727rKk2rjW9l4lNKes8U6f8TG87rD1E7xKnQObMXIMYp6yma-xJUK7HTrbIOlgcKAz0xH0-_-DTnwm2UmtSd861prao1TX_7VWXdef0RVS5B3GkePYKT4w2qmVkP9IsMMp9PqUYdcaeqo3Ub1ADf3juLoO07G6iFQhJVWoR21mv59C16kR5lM7u_agW4aiin-mLFHcitWgKgWI-9pA5aEJWSrVBgpYKq5YJpjdLpVl-Shitrj8ldLiKYzRer1R3BTnXKB6K44FP8Piy1AcrEzcWWAerctKcUctheI-KPeKO9C1od3vm4bl6EbfMBxV2Snu0NJGAjpDwzHt4dAaPKrKb-2ZumZb-sAZWpYxtI2RPTIf_wYi30ch)
---

## üõ†Ô∏è Tech Stack

### Backend
- **Language**: Python 3.11
- **Framework**: LangChain (RAG orchestration)
- **Vector Database**: ChromaDB (semantic search)
- **Embeddings**: Nomic-embed-text via Ollama
- **LLM**: Llama 3.1 70B via Groq API
- **Cache**: Redis 7 (Docker)

### Why These Choices?

**LangChain**: Industry-standard RAG framework with excellent documentation
**ChromaDB**: Lightweight, embeddable vector DB perfect for demos
**Groq**: 10x faster inference than OpenAI, generous free tier
**Redis**: Production-grade caching used by Twitter, GitHub, Stack Overflow

---

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

### Prerequisites
- Python 3.11+
- Docker Desktop
- Groq API Key ([Get free key](https://console.groq.com))

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/codesearch-ai
cd codesearch-ai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Add your GROQ_API_KEY to .env

# Start Redis
docker-compose up -d

# Verify Redis connection
python redis_cache.py
```

### Usage

```python
from chatbot import ReactDotChatbot

# Initialize bot with caching
bot = ReactDotChatbot(use_cache=True)

# Ask a question
response = bot.ask("How do I use the useState hook?")

print(response['answer'])
print(f"Sources: {response['sources']}")
print(f"Cached: {response['cached']}")
print(f"Response time: {response['response_time']}s")
```

---

## üß™ Testing

Run the comprehensive test suite:

```bash
# Test with cache performance tracking
python test_queries_with_cache.py

# Expected output:
# ‚úÖ 25/25 successful queries
# üíæ 42.86% cache hit rate
# ‚ö° 1049x speedup for cached responses
```

---

## üéì Technical Deep-Dive

### RAG Pipeline

1. **Document Processing**
   - Scrape 500+ pages from react.dev
   - Chunk into 1000-token segments with 150-token overlap
   - Preserve metadata (source URLs, headers)

2. **Embedding & Indexing**
   - Generate embeddings using Nomic-embed-text
   - Store in ChromaDB for semantic similarity search
   - ~3 seconds for initial query processing

3. **Retrieval**
   - Convert user query to embedding
   - Find top 3 most relevant document chunks
   - Average retrieval time: 0.5s

4. **Generation**
   - Pass context + query to Llama 3.1 70B
   - Constrained to 300 words for conciseness
   - Include code examples where relevant

5. **Caching**
   - Hash query using MD5
   - Store response in Redis with 24h TTL
   - 1049x speedup on cache hits

### Query Normalization

Improves cache hit rates by normalizing queries:
```python
"How do I use useState?"  ‚Üí "how do i use usestate"
"  useState hook  "       ‚Üí "usestate hook"
```

Result: Similar questions hit the same cache entry.

---

## üìä Evaluation Methodology

### Test Coverage
- **20 unique questions** across difficulty levels
- **5 duplicate questions** to test caching
- Categories: Hooks, Forms, Performance, Advanced Concepts

### Metrics Tracked
- Success rate (all queries answered)
- Response time (overall, cached, uncached)
- Cache hit rate
- Answer quality (code examples included)
- Source relevance

---

## üöÄ Deployment

### Local Development
```bash
docker-compose up -d
python chatbot.py
```

---

## üë§ Author

**Shubham Harkare**
- LinkedIn: [shubham-harkare](https://www.linkedin.com/in/shubham-harkare/)
- GitHub: [@ShubhamHarkare](https://github.com/ShubhamHarkare)
- Portfolio: [website](https://shubham-harkare-owlgiwf.gamma.site)

---


## üìö Resources

- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Groq API Reference](https://console.groq.com/docs)
- [Redis Documentation](https://redis.io/docs/)

---

**Built with ‚ù§Ô∏è for the React developer community**
